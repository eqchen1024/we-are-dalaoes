{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"twitter_nlp.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nXNrwAaQ7tNaTWXdQXImzwQyZmHe6Kvw","authorship_tag":"ABX9TyOTGjSMrCU20ffAbk5Xm8AB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jNpuHHKshnQD","colab_type":"text"},"source":["数据导入"]},{"cell_type":"code","metadata":{"id":"yth-GzUYJtR3","colab_type":"code","colab":{}},"source":["import pandas as pd\n","df=pd.read_csv(r\"/content/drive/My Drive/KAGGLE/nlp/twitter/data/train.csv\")\n","raw_x=df[\"text\"].values.tolist()\n","raw_y=df[\"target\"].values.tolist()\n","raw_data=list(zip(raw_x,raw_y))#x为推特文本 y为是否是灾难的标签"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zu7iYZVoYxwg","colab_type":"text"},"source":["训练测试集划分 保存"]},{"cell_type":"code","metadata":{"id":"MzejK_2sJ05d","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","training_data,test_data=train_test_split(raw_data,test_size=0.2, random_state=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfYySc_zJ98A","colab_type":"code","colab":{}},"source":["train=pd.DataFrame(training_data,columns=[\"text\",\"target\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjH17NZ7KTJB","colab_type":"code","colab":{}},"source":["train.to_csv(\"/content/drive/My Drive/KAGGLE/nlp/twitter/train.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrwqYANyY3pH","colab_type":"text"},"source":["模型及预处理部分"]},{"cell_type":"code","metadata":{"id":"yfbO9qR8g1dw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1596112609247,"user_tz":-480,"elapsed":6081,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}},"outputId":"66e8cd32-3a26-41a5-994a-80c6e3f26b94"},"source":["! pip install pytorch_pretrained_bert"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.1+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.24)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.24)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (1.15.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tGWGZr1ubO1Y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596112615620,"user_tz":-480,"elapsed":4755,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from pytorch_pretrained_bert import BertModel\n","from torch.autograd import Variable\n","#下游任务模型\n","class bigru_attention(nn.Module):\n","    def __init__(self, bert_config, tagset_size, embedding_dim, hidden_dim, rnn_layers, dropout_ratio, dropout1, use_cuda):\n","        super(bigru_attention, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.rnn_layers = rnn_layers\n","        self.word_embeds = BertModel.from_pretrained(bert_config)\n","        # 双向GRU，//操作为了与后面的Attention操作维度匹配，hidden_dim要取偶数！\n","        self.bigru = nn.GRU(embedding_dim, hidden_dim, num_layers=rnn_layers, bidirectional=True,dropout=dropout_ratio, batch_first=True)\n","        self.dropout1 = nn.Dropout(p=dropout1)\n","        # 由nn.Parameter定义的变量都为requires_grad=True状态\n","        self.weight_W = nn.Parameter(torch.Tensor(hidden_dim*2, hidden_dim*2))\n","        self.weight_proj = nn.Parameter(torch.Tensor(hidden_dim*2, 1))\n","        self.fc = nn.Linear(hidden_dim*2,tagset_size)\n","        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n","        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n","        self.use_cuda =  use_cuda\n","\n","    def rand_init_hidden(self, batch_size):\n","        if self.use_cuda:\n","            return Variable(\n","                torch.randn(2 * self.rnn_layers, batch_size, self.hidden_dim)).cuda(), Variable(\n","                torch.randn(2 * self.rnn_layers, batch_size, self.hidden_dim)).cuda()\n","        else:\n","            return Variable(\n","                torch.randn(2 * self.rnn_layers, batch_size, self.hidden_dim)), Variable(\n","                torch.randn(2 * self.rnn_layers, batch_size, self.hidden_dim))\n"," \n","    def forward(self, sentence, attention_mask=None):\n","        batch_size = sentence.size(0)\n","        seq_length = sentence.size(1)\n","        embeds, _ = self.word_embeds(sentence, attention_mask=attention_mask, output_all_encoded_layers=False)\n","        hidden = self.rand_init_hidden(batch_size)\n","        gru_out, hiden = self.bigru(embeds) # [seq_len, bs, hid_dim]\n","        d_gru_out = self.dropout1(gru_out)\n","        x = d_gru_out\n","        # # # Attention过程，与上图中三个公式对应\n","        u = torch.tanh(torch.matmul(x, self.weight_W))\n","        att = torch.matmul(u, self.weight_proj)\n","        att_score = F.softmax(att, dim=1)\n","        scored_x = x * att_score\n","        # # # Attention过程结束\n","        feat = torch.sum(scored_x, dim=1)\n","        y = self.fc(feat)\n","        return y\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j7rygDFb_xgY","colab_type":"text"},"source":["备用"]},{"cell_type":"code","metadata":{"id":"dhEZmhHSgwSP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596112615623,"user_tz":-480,"elapsed":1445,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["import pandas as pd\n","class InputFeatures(object):\n","    def __init__(self, text, label, input_id, input_mask):\n","        self.text = text\n","        self.label = label\n","        self.input_id = input_id\n","        self.input_mask = input_mask\n","#读取bert的词汇表 之后对单词进行编码\n","def load_vocab(vocab_file):\n","    vocab = {}\n","    index = 0\n","    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n","        while True:\n","            token = reader.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            vocab[token] = index\n","            index += 1\n","    return vocab\n","#读取训练 测试文件 分为输入texts 和标签labels\n","def load_file(file_path):\n","    df = pd.read_csv(file_path)\n","    raw_x=df[\"text\"].values.tolist()\n","    raw_y=df[\"target\"].values.tolist()\n","    raw_data=list(zip(raw_x,raw_y))\n","    texts = [[w for w in sample[0].split()] for sample in raw_data]\n","    labels = [sample[1] for sample in raw_data]\n","    return texts, labels\n","#进行对texts进行编码操作 补齐至最大长度\n","def load_data(file_path, max_length, vocab):\n","    texts, labels = load_file(file_path)\n","    assert len(texts) == len(labels)\n","    result = []\n","    for i in range(len(texts)):\n","        token = texts[i]\n","        label = int(labels[i])\n","        if len(token) > max_length-2:\n","            token = token[0:(max_length-2)]\n","        tokens_f =['[CLS]'] + token + ['[SEP]']\n","        input_ids = [int(vocab[i]) if i in vocab else int(vocab['[UNK]']) for i in tokens_f]\n","        mask_bool=1\n","        input_mask = [mask_bool] * len(input_ids)\n","        while len(input_ids) < max_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","        assert len(input_ids) == max_length\n","        assert len(input_mask) == max_length\n","        #assert len(label_ids) == max_length 实体识别标签序列用\n","        feature = InputFeatures(text=tokens_f, label=label, input_id=input_ids, input_mask=input_mask)\n","        result.append(feature)\n","    return result"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"pI5YIPRw4CHk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596112616442,"user_tz":-480,"elapsed":1822,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["#文件位置以及超参数设置\n","save_model_dir='/content/drive/My Drive/KAGGLE/nlp/twitter/'\n","train_file='/content/drive/My Drive/KAGGLE/nlp/twitter/train.csv'\n","dev_file='/content/drive/My Drive/KAGGLE/nlp/twitter/test.csv'\n","max_length=30\n","vocab_file='/content/drive/My Drive/KAGGLE/nlp/twitter/bert/albert_base_v2.zip_files/vocab.txt'\n","batch_size=16\n","tagset_size = 2\n","epochs=20"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JuBKOyCfd_fW","colab_type":"text"},"source":["模型训练及评估"]},{"cell_type":"code","metadata":{"id":"Wc1Gf2c_3NQ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596113860027,"user_tz":-480,"elapsed":1243958,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}},"outputId":"a892b0a8-f419-43f6-fbf6-505019f72b3a"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\", 0)\n","    print('device',device)\n","    use_cuda = True\n","else:\n","    device = torch.device(\"cpu\")\n","    use_cuda = False\n","vocab = load_vocab(vocab_file)\n","#load data\n","train_data = load_data(train_file, max_length=max_length, vocab=vocab)\n","train_ids = torch.LongTensor([temp.input_id for temp in train_data])\n","train_masks = torch.LongTensor([temp.input_mask for temp in train_data])\n","train_tags = torch.LongTensor([temp.label for temp in train_data])\n","train_dataset = TensorDataset(train_ids, train_masks, train_tags)\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","\n","dev_data = load_data(dev_file, max_length=max_length, vocab=vocab)\n","dev_ids = torch.LongTensor([temp.input_id for temp in dev_data])\n","dev_masks = torch.LongTensor([temp.input_mask for temp in dev_data])\n","dev_tags = torch.LongTensor([temp.label for temp in dev_data])\n","dev_dataset = TensorDataset(dev_ids, dev_masks, dev_tags)\n","dev_loader = DataLoader(dev_dataset, shuffle=True, batch_size=batch_size)\n","\n","#模型及超参数设置        \n","model = bigru_attention('bert-base-cased', tagset_size, 768, 200, 1,\n","                      dropout_ratio=0.4, dropout1=0.4, use_cuda = use_cuda)\n","if use_cuda:\n","    model.cuda()\n","model.train()\n","losser=torch.nn.CrossEntropyLoss()\n","optimizer = getattr(optim, 'Adam')#优化器Adam\n","optimizer = optimizer(model.parameters(), lr=0.00003, weight_decay=0.00005)\n","best_f = -100\n","for epoch in range(epochs):\n","    print('epoch: {}trrain'.format(epoch))\n","    for i, train_batch in enumerate(tqdm(train_loader)):\n","        model.train()\n","        model.zero_grad()\n","        sentence, masks, tags = train_batch\n","        sentence, masks, tags = Variable(sentence), Variable(masks), Variable(tags)\n","        if use_cuda:\n","            sentence = sentence.cuda()\n","            masks = masks.cuda()\n","            tags = tags.cuda()\n","        loss = losser(model(sentence),tags)\n","        loss.backward()\n","        optimizer.step()\n","    print('epoch: {}loss: {}'.format(epoch, loss.item()))\n","    model.eval()\n","    pred = []\n","    true=[]\n","    for i, dev_batch in enumerate(dev_loader):#在验证集上验证\n","        model.zero_grad()\n","        sentence, masks, tags = dev_batch\n","        sentence, masks, tags = Variable(sentence), Variable(masks), Variable(tags)\n","        if use_cuda:\n","            sentence = sentence.cuda()\n","            asks = masks.cuda()\n","            tags = tags.cuda()\n","        predict_tags = F.softmax(model(sentence)).tolist()\n","        pred_tag=[i.index(max(i)) for i in predict_tags]\n","        pred.extend(pred_tag)\n","        true.extend(tags.tolist())\n","    print(classification_report(true, pred))\n","    f=f1_score(true, pred)\n","    if f > best_f:#保存最大f1模型\n","        model_name = save_model_dir + '.' + str(epochs) + \".pkl\"\n","        torch.save(model.state_dict(), model_name)\n","        best_f = f"],"execution_count":15,"outputs":[{"output_type":"stream","text":["device cuda:0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 404400730/404400730 [00:11<00:00, 34983575.43B/s]\n","  0%|          | 0/381 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch: 0trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:53<00:00,  7.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 0loss: 0.6927381753921509\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.81      0.82       867\n","           1       0.76      0.76      0.76       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.79      0.79      0.79      1523\n","weighted avg       0.79      0.79      0.79      1523\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:48,  7.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch: 1trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:55<00:00,  6.85it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 1loss: 0.3793383836746216\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.90      0.84       867\n","           1       0.83      0.67      0.74       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.81      0.78      0.79      1523\n","weighted avg       0.80      0.80      0.79      1523\n","\n","epoch: 2trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 2loss: 0.2479133903980255\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:50,  7.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.84      0.82       867\n","           1       0.77      0.71      0.74       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.78      0.78      0.78      1523\n","weighted avg       0.78      0.79      0.78      1523\n","\n","epoch: 3trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 3loss: 0.38025325536727905\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.60it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.87      0.83       867\n","           1       0.80      0.69      0.74       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.79      0.78      0.78      1523\n","weighted avg       0.79      0.79      0.79      1523\n","\n","epoch: 4trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 4loss: 0.15180931985378265\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.91      0.84       867\n","           1       0.85      0.65      0.74       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.81      0.78      0.79      1523\n","weighted avg       0.81      0.80      0.79      1523\n","\n","epoch: 5trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 5loss: 0.0187856312841177\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:50,  7.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.83      0.81       867\n","           1       0.76      0.72      0.74       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.78      0.78      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 6trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 6loss: 0.21643337607383728\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.60it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.91      0.83       867\n","           1       0.84      0.65      0.73       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.81      0.78      0.78      1523\n","weighted avg       0.80      0.80      0.79      1523\n","\n","epoch: 7trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 7loss: 0.0035848976112902164\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.84      0.81       867\n","           1       0.77      0.69      0.73       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.77      0.77      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 8trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 8loss: 0.05913717299699783\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.84      0.82       867\n","           1       0.77      0.72      0.74       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.78      0.78      0.78      1523\n","weighted avg       0.79      0.79      0.79      1523\n","\n","epoch: 9trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 9loss: 0.7772767543792725\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.89      0.83       867\n","           1       0.83      0.67      0.74       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.80      0.78      0.79      1523\n","weighted avg       0.80      0.80      0.79      1523\n","\n","epoch: 10trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 10loss: 0.09321179240942001\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.79      0.79       867\n","           1       0.73      0.73      0.73       656\n","\n","    accuracy                           0.77      1523\n","   macro avg       0.76      0.76      0.76      1523\n","weighted avg       0.77      0.77      0.77      1523\n","\n","epoch: 11trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 11loss: 0.008984637446701527\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.81      0.81       867\n","           1       0.75      0.74      0.74       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.77      0.77      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 12trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 12loss: 0.04183928295969963\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.92      0.83       867\n","           1       0.85      0.62      0.72       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.81      0.77      0.77      1523\n","weighted avg       0.80      0.79      0.78      1523\n","\n","epoch: 13trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 13loss: 0.1595885455608368\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:50,  7.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.84      0.81       867\n","           1       0.76      0.70      0.73       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.77      0.77      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 14trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 14loss: 0.06430454552173615\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.61it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.82      0.81       867\n","           1       0.76      0.73      0.74       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.78      0.78      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 15trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 15loss: 0.1790878027677536\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:50,  7.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.85      0.82       867\n","           1       0.78      0.69      0.73       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.77      0.77      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 16trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 16loss: 0.0005979061243124306\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.84      0.82       867\n","           1       0.77      0.70      0.74       656\n","\n","    accuracy                           0.78      1523\n","   macro avg       0.78      0.77      0.78      1523\n","weighted avg       0.78      0.78      0.78      1523\n","\n","epoch: 17trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 17loss: 0.1405123770236969\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:50,  7.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.87      0.83       867\n","           1       0.80      0.69      0.74       656\n","\n","    accuracy                           0.79      1523\n","   macro avg       0.80      0.78      0.79      1523\n","weighted avg       0.80      0.79      0.79      1523\n","\n","epoch: 18trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 18loss: 0.08097044378519058\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/381 [00:00<00:49,  7.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.91      0.84       867\n","           1       0.84      0.64      0.73       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.81      0.78      0.78      1523\n","weighted avg       0.80      0.80      0.79      1523\n","\n","epoch: 19trrain\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 381/381 [00:56<00:00,  6.71it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 19loss: 0.0027462481521070004\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.92      0.84       867\n","           1       0.86      0.64      0.73       656\n","\n","    accuracy                           0.80      1523\n","   macro avg       0.82      0.78      0.79      1523\n","weighted avg       0.81      0.80      0.79      1523\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RZOZ4vhyob73","colab_type":"text"},"source":["预测"]},{"cell_type":"code","metadata":{"id":"47f0j3qQYksn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596114382462,"user_tz":-480,"elapsed":7815,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}},"outputId":"fd4f7964-056d-49d1-c0c6-4d7f7c7b2b11"},"source":["import torch\n","model =bigru_attention('bert-base-cased', tagset_size, 768, 200, 1,\n","                      dropout_ratio=0.4, dropout1=0.4, use_cuda = True)\n","model.load_state_dict(torch.load('/content/drive/My Drive/KAGGLE/nlp/twitter/.20.pkl'))#读取保存的模型参数\n","model.cuda()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["bigru_attention(\n","  (word_embeds): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bigru): GRU(768, 200, batch_first=True, dropout=0.4, bidirectional=True)\n","  (dropout1): Dropout(p=0.4, inplace=False)\n","  (fc): Linear(in_features=400, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"HZxPh97OD5Dn","colab_type":"text"},"source":["预测测试集"]},{"cell_type":"code","metadata":{"id":"scK4ibPA2Nxo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114661102,"user_tz":-480,"elapsed":1353,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["test_file='/content/drive/My Drive/KAGGLE/nlp/twitter/data/test.csv'#读取测试集"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9iO1WIdEZtW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114884956,"user_tz":-480,"elapsed":1074,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["class InputTestFeatures(object):\n","    def __init__(self, text, input_id, input_mask):\n","        self.text = text\n","        self.input_id = input_id\n","        self.input_mask = input_mask\n","def load_test_file(file_path):\n","    df = pd.read_csv(file_path)\n","    raw_x=df[\"text\"].values.tolist()\n","    texts = [[w for w in sample.split()] for sample in raw_x]\n","    return texts\n","def load_test_data(file_path, max_length, vocab):\n","    texts = load_test_file(file_path)\n","    result = []\n","    for i in range(len(texts)):\n","        token = texts[i]\n","        if len(token) > max_length-2:\n","            token = token[0:(max_length-2)]\n","        tokens_f =['[CLS]'] + token + ['[SEP]']\n","        input_ids = [int(vocab[i]) if i in vocab else int(vocab['[UNK]']) for i in tokens_f]\n","        mask_bool=1\n","        input_mask = [mask_bool] * len(input_ids)\n","        while len(input_ids) < max_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","        assert len(input_ids) == max_length\n","        assert len(input_mask) == max_length\n","        feature = InputTestFeatures(text=tokens_f, input_id=input_ids, input_mask=input_mask)\n","        result.append(feature)\n","    return result\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-4z3gkC2P5K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596115279539,"user_tz":-480,"elapsed":834,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["#准备测试数据\n","test_data = load_test_data(test_file, max_length=max_length, vocab=vocab)\n","test_ids = torch.LongTensor([temp.input_id for temp in test_data])\n","test_masks = torch.LongTensor([temp.input_mask for temp in test_data])\n","test_dataset = TensorDataset(test_ids, test_masks)\n","test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jYzUHFIEAbP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596115330568,"user_tz":-480,"elapsed":8467,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["#测试\n","model.eval()\n","pred = []\n","for i, test_batch in enumerate(test_loader):\n","    model.zero_grad()\n","    sentence, masks= test_batch\n","    sentence, masks= Variable(sentence), Variable(masks)\n","    if use_cuda:\n","        sentence = sentence.cuda()\n","        asks = masks.cuda()\n","        tags = tags.cuda()\n","    predict_tags = F.softmax(model(sentence)).tolist()\n","    pred_tag=[i.index(max(i)) for i in predict_tags]\n","    pred.extend(pred_tag)"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SbBddI5b8Gy4","colab_type":"text"},"source":["保存预测的测试数据"]},{"cell_type":"code","metadata":{"id":"dGmKQ9YJ3Z2D","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596115338513,"user_tz":-480,"elapsed":698,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["id=df[\"id\"].values.tolist()"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rmj4OxxO3lE7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596115525146,"user_tz":-480,"elapsed":931,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["res_df=pd.DataFrame(zip(id,pred),columns=[\"id\",\"target\"])"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6zltlsG5jcV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596115675712,"user_tz":-480,"elapsed":800,"user":{"displayName":"dy c","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwUhiP2JGBJF0ccdzeCMO3DywIn5WL-okr917K=s64","userId":"07027550308680493425"}}},"source":["res_df.to_csv(\"/content/drive/My Drive/KAGGLE/nlp/twitter/submission.csv\",index=None)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfSggTEn5zWC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}